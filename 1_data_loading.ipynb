{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTLP Embeddings\n",
    "\n",
    "This notebook:\n",
    "- Reads OpenTelemetry traces in protobuf format into a custom JSON model\n",
    "- Generates embeddings via the AzureAI API\n",
    "- Stores the results in a vector database running locally (`qdrant`) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_name = 'baseline'\n",
    "#ds_name = 'live_add_brazil'\n",
    "#ds_name = 'live_high_uk_latency'\n",
    "#ds_name = 'live_unseen_exception_type'\n",
    "\n",
    "dir = f'D:\\source\\OpenAiAlerting-Python\\data\\{ds_name}'\n",
    "col_name = ds_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define logic to convert proto traces to our format.\n",
    "\n",
    "import json\n",
    "from opentelemetry.proto.trace.v1 import trace_pb2\n",
    "\n",
    "class Trace:\n",
    "    def __init__(self, trace_id, root_span):\n",
    "        self.trace_id = trace_id\n",
    "        self.root_span = root_span\n",
    "\n",
    "    def to_json(self):\n",
    "        return json.dumps(self.root_span.to_json_dict(), default=lambda o : o.to_json_dict() if isinstance(o, Span) else o.__dict__)\n",
    "\n",
    "class Span:\n",
    "    def __init__(self, span_id, parent_span_id, operation_name, client_or_server, duration_ms, service_name, service_version, attributes, events):\n",
    "        self.operation_name = operation_name\n",
    "        self.span_id = span_id\n",
    "        self.parent_span_id = parent_span_id\n",
    "        self.client_or_server = client_or_server\n",
    "        self.duration_ms = duration_ms\n",
    "        self.service_name = service_name\n",
    "        self.service_version = service_version\n",
    "        self.attributes = attributes\n",
    "        self.events = events\n",
    "        self.child_spans = []\n",
    "\n",
    "    def add_child(self, span):\n",
    "        if span.parent_span_id == self.span_id:\n",
    "            self.child_spans.append(span)\n",
    "            return self\n",
    "        elif span.span_id == self.parent_span_id:\n",
    "            span.add_child(self)\n",
    "            return span\n",
    "        else:\n",
    "            for child in self.child_spans:\n",
    "                newRoot = child.add_child(span)\n",
    "                if newRoot != None:\n",
    "                    self.child_spans.remove(child)\n",
    "                    self.child_spans.append(newRoot)\n",
    "                    return self\n",
    "\n",
    "    def to_json_dict(self):\n",
    "        clone = self.__dict__.copy()\n",
    "        clone.pop('span_id', None)\n",
    "        clone.pop('parent_span_id', None)\n",
    "        return clone\n",
    "                \n",
    "def convert_trace(trace):\n",
    "    all_spans = []\n",
    "    trace_id = ''\n",
    "    \n",
    "    for resource_span in trace.resource_spans:\n",
    "        resource_attrs = { x.key: x.value.string_value for x in resource_span.resource.attributes}\n",
    "        service_name = resource_attrs['service.name']\n",
    "        service_version = resource_attrs['service.version']\n",
    "\n",
    "        for scope_span in resource_span.scope_spans:\n",
    "            for span in scope_span.spans:\n",
    "                trace_id = span.trace_id.hex()\n",
    "                op_name = span.name\n",
    "                span_id = span.span_id.hex()\n",
    "                parent_span_id = span.parent_span_id.hex()\n",
    "                client_or_server = \"client\" if span.kind == trace_pb2.Span.SPAN_KIND_CLIENT else \"server\"\n",
    "                duration_ms = (span.end_time_unix_nano - span.start_time_unix_nano) / 1e6\n",
    "                attributes = { x.key: x.value.string_value or x.value.int_value for x in span.attributes }\n",
    "                events = []\n",
    "                for e in span.events:\n",
    "                    events.append({'type': e.name, 'attributes': {x.key: x.value.string_value or x.value.int_value for x in e.attributes }})\n",
    "\n",
    "                all_spans.append(Span(span_id, parent_span_id, op_name, client_or_server, duration_ms, service_name, service_version, attributes, events))\n",
    "    \n",
    "    root_span = None\n",
    "\n",
    "    for span in all_spans:\n",
    "        if root_span is None:\n",
    "            root_span = span\n",
    "        else:\n",
    "            root_span = root_span.add_child(span)\n",
    "\n",
    "    return Trace(trace_id, root_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load protobuf files, convert to our schema, add to traces array.\n",
    "import os\n",
    "\n",
    "files = os.listdir(dir)\n",
    "\n",
    "traces = []\n",
    "\n",
    "for f_name in files:\n",
    "    proto_trace = trace_pb2.TracesData()\n",
    "\n",
    "    with open(os.path.join(dir, f_name), \"rb\") as f:\n",
    "        proto_trace.ParseFromString(f.read())\n",
    "\n",
    "    traces.append(convert_trace(proto_trace))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 323085, min: 567, max: 1890, median: 570.0, total_cost: £0.03\n"
     ]
    }
   ],
   "source": [
    "# Get token sizes and total to calculate pricing\n",
    "\n",
    "import tiktoken\n",
    "import statistics\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "tokens = []\n",
    "\n",
    "for t in traces:\n",
    "  data = t.to_json()\n",
    "  tokens.append(len(tokenizer.encode(data)))\n",
    "  \n",
    "print(f'total: {sum(tokens)}, min: {min(tokens)}, max: {max(tokens)}, median: {statistics.median(tokens)}, total_cost: £{round(sum(tokens) / 1000 * 0.000079, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed 50/500 traces\n",
      "completed 100/500 traces\n",
      "completed 150/500 traces\n",
      "completed 200/500 traces\n",
      "completed 250/500 traces\n",
      "completed 300/500 traces\n",
      "completed 350/500 traces\n",
      "completed 400/500 traces\n",
      "completed 450/500 traces\n",
      "completed 500/500 traces\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for each trace, then add to map[trace_id] -> embedding vector\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key = \"secret-key\",  \n",
    "  api_version = \"2023-05-15\",\n",
    "  azure_endpoint = \"https://blake.openai.azure.com/\"\n",
    ")\n",
    "\n",
    "trace_embeddings = {}\n",
    "\n",
    "for (i, trace) in enumerate(traces):\n",
    "  data = trace.to_json()\n",
    "  \n",
    "  response = client.embeddings.create(\n",
    "      input = data,\n",
    "      model= \"text-embedding-ada-002\"\n",
    "  )\n",
    "\n",
    "  trace_embeddings[trace.trace_id] = response.data[0].embedding\n",
    "\n",
    "  i += 1\n",
    "  if i % 50 == 0:\n",
    "    print(f'completed {i}/{len(traces)} traces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a collection in qdrant for storing the historic embeddings\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "q_client = QdrantClient(\"localhost\", port=6333)\n",
    "\n",
    "q_client.create_collection(\n",
    "    collection_name=col_name,\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operation_id=0 status=<UpdateStatus.COMPLETED: 'completed'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Insert the historic traces into the collection\n",
    "from qdrant_client.http.models import PointStruct\n",
    "\n",
    "def dfs_find_span(op_name, service_name):\n",
    "    stack = [t.root_span]\n",
    "    visited = set()\n",
    "    temp = 0\n",
    "\n",
    "    while stack:\n",
    "        vertex = stack.pop()\n",
    "\n",
    "        if vertex in visited:\n",
    "            continue\n",
    "        if vertex.operation_name == op_name and vertex.service_name == service_name:\n",
    "            return vertex\n",
    "            \n",
    "        visited.add(vertex)\n",
    "        stack.extend(vertex.child_spans)\n",
    "    \n",
    "    return None\n",
    "\n",
    "id = 1\n",
    "points = []\n",
    "for t in traces:\n",
    "    vector = trace_embeddings[t.trace_id]\n",
    "    payload = {\n",
    "        'duration': t.root_span.duration_ms,\n",
    "        'http.request.method': t.root_span.attributes['http.request.method'],\n",
    "        'http.response.status_code': t.root_span.attributes['http.response.status_code']\n",
    "    }\n",
    "\n",
    "    if 'user.country' in t.root_span.attributes:\n",
    "        payload['country'] = t.root_span.attributes['user.country']\n",
    "\n",
    "    forecast_svc_span = dfs_find_span('GET WeatherForecast/GetForecastForUser', 'ForecastService')\n",
    "\n",
    "    if 'error.type' in forecast_svc_span.attributes:\n",
    "        payload['error.type'] = forecast_svc_span.attributes['error.type']\n",
    "\n",
    "    if 'forecast.temperatureC' in forecast_svc_span.attributes:\n",
    "        payload['forecast.temperatureC'] = forecast_svc_span.attributes['forecast.temperatureC']\n",
    "\n",
    "    points.append(PointStruct(id=id, vector=vector, payload=payload))\n",
    "    id += 1\n",
    "\n",
    "operation_info = q_client.upsert(\n",
    "    collection_name=col_name,\n",
    "    wait=True,\n",
    "    points=points\n",
    ")\n",
    "\n",
    "print(operation_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
